{
  "project": "RDI-AgentBeats-GraphJudge",
  "description": "Graph-Based Coordination Benchmark - Green Agent (Assessor) for evaluating multi-agent coordination quality through runtime graph analysis, LLM assessment, and latency metrics.",
  "source": "GreenAgent-PRD.md",
  "generated": "2026-01-31 02:32:03",
  "stories": [
    {
      "id": "STORY-001",
      "title": "Messenger with A2A SDK + extensions",
      "description": "Implement Messenger class using A2A SDK for authentic agent-to-agent communication via JSON-RPC protocol. Supports A2A Traceability Extension for distributed call tracing.",
      "acceptance": [
        "Messenger uses ClientFactory.connect() from a2a-sdk",
        "Messages created via create_text_message_object()",
        "Response extracted from TaskState.completed events",
        "Client caching per agent URL implemented",
        "All tests pass: uv run pytest tests/test_messenger.py"
      ],
      "files": [
        "src/green/messenger.py",
        "tests/test_messenger.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T17:30:00Z",
      "content_hash": "a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2",
      "depends_on": []
    },
    {
      "id": "STORY-002",
      "title": "InteractionStep model integration",
      "description": "Extend models to support InteractionStep conforming to A2A Traceability Extension Step specification.",
      "acceptance": [
        "InteractionStep model with step_id, trace_id, call_type, start_time, end_time",
        "CallType enum: AGENT, TOOL, HOST",
        "Model includes latency, error, parent_step_id fields",
        "All tests pass: uv run pytest tests/test_models.py"
      ],
      "files": [
        "src/green/models.py",
        "tests/test_models.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T17:45:00Z",
      "content_hash": "b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3",
      "depends_on": [
        "STORY-001"
      ]
    },
    {
      "id": "STORY-003",
      "title": "Executor with trace collection and cleanup",
      "description": "Implement Executor class for task execution, trace collection, and resource cleanup.",
      "acceptance": [
        "Executor coordinates messenger, evaluators, and result aggregation",
        "Trace collection during task execution",
        "Calls messenger.close() after trace collection",
        "All tests pass: uv run pytest tests/test_executor.py"
      ],
      "files": [
        "src/green/executor.py",
        "tests/test_executor.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:00:00Z",
      "content_hash": "c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4",
      "depends_on": [
        "STORY-002"
      ]
    },
    {
      "id": "STORY-004",
      "title": "Add OpenAI dependency to pyproject.toml",
      "description": "Add openai>=1.0 to project dependencies for LLM-based evaluation support.",
      "acceptance": [
        "openai>=1.0 in pyproject.toml dependencies",
        "uv sync succeeds",
        "Import openai works in Python"
      ],
      "files": [
        "pyproject.toml"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:05:00Z",
      "content_hash": "d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5",
      "depends_on": [
        "STORY-003"
      ]
    },
    {
      "id": "STORY-005",
      "title": "Green Agent business logic (agent.py)",
      "description": "Implement Agent class for evaluation orchestration logic.",
      "acceptance": [
        "Agent class coordinates calls to evaluators",
        "Aggregates evaluation results into structured response",
        "All tests pass: uv run pytest tests/test_agent.py"
      ],
      "files": [
        "src/green/agent.py",
        "tests/test_agent.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:15:00Z",
      "content_hash": "e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6",
      "depends_on": [
        "STORY-004"
      ]
    },
    {
      "id": "STORY-006",
      "title": "Green Agent A2A HTTP server (server.py)",
      "description": "Implement A2A HTTP server with CLI args, AgentCard endpoint, health checks, and task delegation.",
      "acceptance": [
        "FastAPI server with AgentCard at /.well-known/agent-card.json",
        "Health check endpoint at /health",
        "JSON-RPC handler for message/send",
        "Writes results to output/results.json",
        "All tests pass: uv run pytest tests/test_server.py"
      ],
      "files": [
        "src/green/server.py",
        "tests/test_server.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:30:00Z",
      "content_hash": "f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7",
      "depends_on": [
        "STORY-005"
      ]
    },
    {
      "id": "STORY-007",
      "title": "LLM client configuration with environment variables",
      "description": "Implement LLM client configuration supporting environment variables for API key, base URL, and model selection.",
      "acceptance": [
        "Reads AGENTBEATS_LLM_API_KEY, AGENTBEATS_LLM_BASE_URL, AGENTBEATS_LLM_MODEL",
        "Default base URL: https://api.openai.com/v1",
        "Default model: gpt-4o-mini",
        "All tests pass: uv run pytest tests/test_llm_judge.py"
      ],
      "files": [
        "src/green/evals/llm_judge.py",
        "src/green/settings.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:09:31Z",
      "content_hash": "a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8",
      "depends_on": [
        "STORY-006"
      ]
    },
    {
      "id": "STORY-008",
      "title": "LLM prompt engineering for coordination assessment",
      "description": "Design and implement LLM prompt for semantic assessment of coordination quality.",
      "acceptance": [
        "Prompt includes TraceData serialization",
        "Requests overall_score, reasoning, coordination_quality",
        "JSON schema for LLMJudgment response",
        "All tests pass"
      ],
      "files": [
        "src/green/evals/llm_judge.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:13:01Z",
      "content_hash": "b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9",
      "depends_on": [
        "STORY-007"
      ]
    },
    {
      "id": "STORY-009",
      "title": "LLM API integration with fallback to rule-based evaluation",
      "description": "Integrate LLM API calls with graceful fallback to rule-based evaluation if API unavailable.",
      "acceptance": [
        "Falls back to rule-based if API unavailable",
        "Uses temperature=0 for consistency",
        "Handles API errors gracefully",
        "All tests pass"
      ],
      "files": [
        "src/green/evals/llm_judge.py",
        "tests/test_llm_judge.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:16:51Z",
      "content_hash": "c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0",
      "depends_on": [
        "STORY-008"
      ]
    },
    {
      "id": "STORY-010",
      "title": "Latency metrics evaluator",
      "description": "Implement latency metrics evaluator for comparative analysis within same system environment.",
      "acceptance": [
        "Reads latency from InteractionStep.latency field",
        "Computes percentiles: avg, p50, p95, p99",
        "Identifies slowest agent by URL",
        "All tests pass: uv run pytest tests/test_system.py"
      ],
      "files": [
        "src/green/evals/system.py",
        "tests/test_system.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:28:25Z",
      "content_hash": "d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1",
      "depends_on": [
        "STORY-009"
      ]
    },
    {
      "id": "STORY-011",
      "title": "Wire all evaluators in Executor pipeline",
      "description": "Integrate all evaluators (Graph, LLM Judge, Latency) into Executor pipeline.",
      "acceptance": [
        "Executor calls all evaluators in correct order",
        "Results aggregated into structured response",
        "Output follows AgentBeats leaderboard standard",
        "All tests pass"
      ],
      "files": [
        "src/green/executor.py",
        "tests/test_executor.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T18:36:10Z",
      "content_hash": "e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2",
      "depends_on": [
        "STORY-003",
        "STORY-010"
      ]
    },
    {
      "id": "STORY-012",
      "title": "Extensibility documentation and examples",
      "description": "Document evaluator interface pattern and provide examples for adding custom evaluators.",
      "acceptance": [
        "Documentation explains evaluator interface pattern",
        "Tier-based structure documented",
        "Example evaluator implementation provided",
        "Integration points clearly described"
      ],
      "files": [
        "docs/AgentBeats/AGENTBEATS_REGISTRATION.md"
      ],
      "passes": true,
      "completed_at": "2026-01-27T19:00:26Z",
      "content_hash": "f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3",
      "depends_on": [
        "STORY-011"
      ]
    },
    {
      "id": "STORY-013",
      "title": "Graph evaluator test suite",
      "description": "Implement comprehensive test suite for graph-based coordination analysis.",
      "acceptance": [
        "Tests validate metric computation",
        "Tests validate bottleneck detection",
        "All tests pass: uv run pytest tests/test_graph.py"
      ],
      "files": [
        "tests/test_graph.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T19:08:03Z",
      "content_hash": "a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4",
      "depends_on": [
        "STORY-003"
      ]
    },
    {
      "id": "STORY-014",
      "title": "Graph-based coordination analysis implementation",
      "description": "Implement graph-based coordination analysis with pluggable metric system.",
      "acceptance": [
        "Builds directed graph from TraceData",
        "Computes centrality, density, clustering metrics",
        "Identifies bottlenecks and isolated agents",
        "All tests pass"
      ],
      "files": [
        "src/green/evals/graph.py",
        "tests/test_graph.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T19:15:30Z",
      "content_hash": "b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5",
      "depends_on": [
        "STORY-013"
      ]
    },
    {
      "id": "STORY-015",
      "title": "Base Purple Agent implementation",
      "description": "Implement Base Purple Agent as A2A-compliant test fixture for E2E validation.",
      "acceptance": [
        "Purple Agent follows RDI green-agent-template pattern",
        "AgentCard at /.well-known/agent-card.json",
        "Handles message/send JSON-RPC method",
        "All tests pass: uv run pytest tests/test_purple_agent.py"
      ],
      "files": [
        "src/purple/server.py",
        "src/purple/executor.py",
        "src/purple/settings.py",
        "tests/test_purple_agent.py"
      ],
      "passes": true,
      "completed_at": "2026-01-27T19:46:55Z",
      "content_hash": "c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6",
      "depends_on": [
        "STORY-003"
      ]
    },
    {
      "id": "STORY-016",
      "title": "E2E test suite with ground truth validation",
      "description": "Implement E2E test suite validating both agents' AgentCards and Green Agent evaluation correctness.",
      "acceptance": [
        "E2E tests validate both agents' AgentCards are accessible",
        "E2E tests verify Purple Agent generates expected outputs",
        "E2E tests verify Green Agent correctly classifies scenarios",
        "All tests pass"
      ],
      "files": [
        "tests/e2e/",
        "data/ground_truth.json"
      ],
      "passes": true,
      "completed_at": "2026-01-27T19:57:02Z",
      "content_hash": "d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7",
      "depends_on": [
        "STORY-015",
        "STORY-011"
      ]
    },
    {
      "id": "STORY-017",
      "title": "Create demo video script",
      "description": "Create comprehensive demo video script showcasing Green Agent capabilities.",
      "acceptance": [
        "Script includes narration and screen actions",
        "Covers key features and evaluation pipeline",
        "Timing cues included"
      ],
      "files": [
        "docs/demo_script.md"
      ],
      "passes": true,
      "completed_at": "2026-01-27T21:10:48Z",
      "content_hash": "e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8",
      "depends_on": [
        "STORY-011"
      ]
    },
    {
      "id": "STORY-018",
      "title": "Common module with shared models",
      "description": "Create common module with shared models (CallType, InteractionStep, JSONRPCRequest/Response) for use by both Green and Purple agents.",
      "acceptance": [
        "src/common/__init__.py exports all shared types",
        "src/common/models.py contains CallType, InteractionStep, JSONRPCRequest, JSONRPCResponse",
        "Models conform to A2A Traceability Extension Step specification",
        "Green agent re-exports from common (backward compatible)",
        "All tests pass: uv run pytest tests/test_common_models.py"
      ],
      "files": [
        "src/common/__init__.py",
        "src/common/models.py",
        "src/green/models.py",
        "tests/test_common_models.py"
      ],
      "passes": true,
      "completed_at": "2026-01-31T20:31:53Z",
      "content_hash": "f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9",
      "depends_on": [
        "STORY-003"
      ]
    },
    {
      "id": "STORY-019",
      "title": "Common LLM settings and client factory",
      "description": "Create shared LLMSettings and LLM client factory in common module.",
      "acceptance": [
        "src/common/settings.py contains LLMSettings class",
        "LLMSettings supports env vars: AGENTBEATS_LLM_API_KEY, AGENTBEATS_LLM_BASE_URL, AGENTBEATS_LLM_MODEL",
        "src/common/llm_client.py provides create_llm_client() factory",
        "Green agent uses common LLMSettings (backward compatible)",
        "All tests pass: uv run pytest tests/test_common_llm.py"
      ],
      "files": [
        "src/common/settings.py",
        "src/common/llm_client.py",
        "src/green/settings.py",
        "tests/test_common_llm.py"
      ],
      "passes": true,
      "completed_at": "2026-01-31T20:38:08Z",
      "content_hash": "a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0",
      "depends_on": [
        "STORY-018"
      ]
    },
    {
      "id": "STORY-020",
      "title": "Common messenger",
      "description": "Move messenger implementation to common module, eliminating code duplication.",
      "acceptance": [
        "src/common/messenger.py contains A2A Messenger implementation",
        "Messenger uses ClientFactory.connect() from a2a-sdk",
        "Green and Purple agents re-export from common",
        "Backward compatible imports maintained",
        "All tests pass: uv run pytest tests/test_common_messenger.py"
      ],
      "files": [
        "src/common/messenger.py",
        "src/green/messenger.py",
        "src/purple/messenger.py",
        "tests/test_common_messenger.py"
      ],
      "passes": true,
      "completed_at": "2026-01-31T20:50:13Z",
      "content_hash": "b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1",
      "depends_on": [
        "STORY-018"
      ]
    },
    {
      "id": "STORY-021",
      "title": "Trace reporter for async trace collection",
      "description": "Create TraceReporter for async fire-and-forget trace reporting from Purple agents to Green.",
      "acceptance": [
        "src/common/trace_reporter.py contains TraceReporter class",
        "TraceReporter sends traces to Green's /traces endpoint",
        "Fire-and-forget pattern (non-blocking)",
        "Graceful handling of Green unavailability",
        "All tests pass: uv run pytest tests/test_common_trace_reporter.py"
      ],
      "files": [
        "src/common/trace_reporter.py",
        "tests/test_common_trace_reporter.py"
      ],
      "passes": true,
      "completed_at": "2026-01-31T20:53:45Z",
      "content_hash": "c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2",
      "depends_on": [
        "STORY-018"
      ]
    },
    {
      "id": "STORY-022",
      "title": "Peer discovery",
      "description": "Create PeerDiscovery for discovering peer agents via static configuration and Green registry.",
      "acceptance": [
        "src/common/peer_discovery.py contains PeerDiscovery class",
        "Supports static peers configuration",
        "Supports Green registry lookup via /peers endpoint",
        "Caches peer list with configurable TTL",
        "All tests pass: uv run pytest tests/test_common_peer_discovery.py"
      ],
      "files": [
        "src/common/peer_discovery.py",
        "tests/test_common_peer_discovery.py"
      ],
      "passes": true,
      "completed_at": "2026-01-31T21:43:29Z",
      "content_hash": "d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3",
      "depends_on": [
        "STORY-018"
      ]
    },
    {
      "id": "STORY-023",
      "title": "Green trace collector endpoints",
      "description": "Add /traces, /register, and /peers endpoints to Green agent for trace collection and agent registry.",
      "acceptance": [
        "POST /traces endpoint receives async trace reports",
        "POST /register endpoint registers agents in Green's registry",
        "GET /peers endpoint returns list of registered agent URLs",
        "src/green/trace_store.py provides in-memory trace storage",
        "All tests pass: uv run pytest tests/test_green_trace_store.py tests/test_green_server_traces.py"
      ],
      "files": [
        "src/green/trace_store.py",
        "src/green/server.py",
        "tests/test_green_trace_store.py",
        "tests/test_green_server_traces.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4",
      "depends_on": [
        "STORY-011",
        "STORY-021"
      ]
    }
  ]
}
